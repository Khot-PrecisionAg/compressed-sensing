{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy as cp\n",
    "from scipy.linalg import qr\n",
    "from scipy.fftpack import idct, dct\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams.update({'font.size': 14}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"\"  # Update with your actual file path\n",
    "df = pd.read_csv(file_path, parse_dates=[\"datetime\"])\n",
    "\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_sensors(df, field, variable, scaler, figure, yticks, subfig):\n",
    "    df = df[(df[\"field\"] == field) &\n",
    "        (df[\"datetime\"].dt.year.isin([2023, 2024])) \n",
    "        &\n",
    "        (df[\"datetime\"].dt.month.isin([3, 4]))\n",
    "        ]\n",
    "    \n",
    "    df = df[[\"datetime\", \"location\", variable]]\n",
    "\n",
    "    pivot_air = df.pivot(index=\"datetime\", columns=\"location\", values=variable)\n",
    "\n",
    "    pivot_air = pivot_air.dropna()\n",
    "    print(pivot_air)\n",
    "    # Convert to matrix with rows = sensor nodes, columns = time\n",
    "    WSN_matrix = pivot_air.to_numpy().T\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    WSN_matrix_scaled = scaler.fit_transform(WSN_matrix)\n",
    "\n",
    "    num_sensors = 6\n",
    "    num_timestamps = WSN_matrix_scaled.shape[1]  # Length of time-series\n",
    "\n",
    "    # Assuming WSN_matrix_scaled is preprocessed & standardized\n",
    "\n",
    "    # Extract timestamps from pivot_air\n",
    "    timestamps = pivot_air.index  # Assuming pivot_air has datetime index\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # QR Pivoting for Sensor Selection\n",
    "    # -----------------------------------------\n",
    "    def qr_pivoting(matrix, num_selected_sensors):\n",
    "        \"\"\" Perform QR Pivoting to select optimal sensors. \"\"\"\n",
    "        _, _, pivoting = qr(matrix.T, pivoting=True)\n",
    "        return pivoting[:num_selected_sensors]\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # Construct Measurement Matrix (DCT Basis)\n",
    "    # -----------------------------------------\n",
    "    def construct_dct_matrix(sensor_indices, num_sensors):\n",
    "        \"\"\" Construct a Discrete Cosine Transform (DCT) measurement matrix. \"\"\"\n",
    "        I = np.eye(num_sensors)\n",
    "        Theta = np.array([dct(I[:, i], norm=\"ortho\") for i in sensor_indices])\n",
    "        return Theta\n",
    "\n",
    "    # --------------------------------------\n",
    "    # Sparse Recovery Problem Using L1-Minimization\n",
    "    # ----------------------------------------\n",
    "    def compressed_sensing_reconstruction(Theta, measurements):\n",
    "        \"\"\" Solve L2-minimization problem using Lasso to recover missing sensor data. \"\"\"\n",
    "        a = cp.Variable(num_sensors)\n",
    "        objective = cp.Minimize(cp.norm(a, 2))\n",
    "        constraints = [Theta @ a == measurements]\n",
    "        prob = cp.Problem(objective, constraints)\n",
    "        prob.solve()\n",
    "        return a.value  \n",
    "\n",
    "    # -----------------------------------------\n",
    "    # Loop Over Increasing Number of Selected Sensors\n",
    "    # -----------------------------------------\n",
    "    rmse_values = []\n",
    "    sensor_counts = list(range(1, num_sensors))  # Varying number of sensors\n",
    "    print(qr_pivoting(WSN_matrix_scaled, 6))\n",
    "\n",
    "    for num_selected_sensors in sensor_counts:\n",
    "        # Select training sensors using QR pivoting\n",
    "        selected_sensors = qr_pivoting(WSN_matrix_scaled, num_selected_sensors)\n",
    "        \n",
    "        rmse_fold = []  # Store RMSE for each leave-one-out validation\n",
    "        \n",
    "        for validation_sensor in range(num_sensors):  # Leave-One-Out\n",
    "            if validation_sensor in selected_sensors:\n",
    "                continue  # Skip if already in selected sensors\n",
    "\n",
    "            print(f\"Training Sensors: {selected_sensors}, Validation Sensor: {validation_sensor}\")\n",
    "            \n",
    "            # Training Data (Remove Validation Sensor)\n",
    "            X_train = WSN_matrix_scaled[selected_sensors, :]\n",
    "            X_valid = WSN_matrix_scaled[validation_sensor, :]  # Left-out sensor\n",
    "\n",
    "            # Construct DCT Measurement Matrix\n",
    "            Theta = construct_dct_matrix(selected_sensors, num_sensors)\n",
    "\n",
    "            # Initialize Reconstructed Signal\n",
    "            reconstructed_signal = np.zeros(num_timestamps)\n",
    "\n",
    "            # Apply compressed sensing for each time step\n",
    "            for t in range(num_timestamps):\n",
    "                y_t = X_train[:, t]  # Observed measurements at time t\n",
    "                a_opt = compressed_sensing_reconstruction(Theta, y_t)\n",
    "\n",
    "                if a_opt is not None and len(a_opt) == num_sensors:\n",
    "                    reconstructed_signal[t] = idct(a_opt, norm=\"ortho\")[validation_sensor]\n",
    "                else:\n",
    "                    reconstructed_signal[t] = np.nan  # If reconstruction fails, assign NaN\n",
    "\n",
    "            # Compute RMSE for this validation sensor\n",
    "            true_signal = scaler.inverse_transform(WSN_matrix_scaled)[validation_sensor, :]\n",
    "            reconstructed_signal_scaled = scaler.inverse_transform(reconstructed_signal.reshape(1, -1)).T\n",
    "\n",
    "            rmse = np.sqrt(mean_squared_error(true_signal, reconstructed_signal_scaled))\n",
    "            rmse_fold.append(rmse)\n",
    "\n",
    "            print(f\"Validation Sensor {validation_sensor}: RMSE = {rmse:.2f}\")\n",
    "\n",
    "        # Store the mean RMSE for this sensor count\n",
    "        mean_rmse = np.mean(rmse_fold)\n",
    "        rmse_values.append(mean_rmse)\n",
    "\n",
    "        print(f\"Sensors Used: {num_selected_sensors}, Mean RMSE: {mean_rmse:.2f}\")\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # Plot RMSE vs Number of Selected Sensors\n",
    "    # -----------------------------------------\n",
    "\n",
    "\n",
    "    # Find the first index where RMSE starts increasing\n",
    "    increase_idx = np.where(np.diff(rmse_values) > 0)[0]  # Get increasing indices\n",
    "\n",
    "    if len(increase_idx) > 0:\n",
    "        first_increase_idx = increase_idx[0]  # Adjust for diff() shift\n",
    "        highlight_x = sensor_counts[first_increase_idx]\n",
    "        highlight_y = rmse_values[first_increase_idx]\n",
    "    else:\n",
    "        highlight_x, highlight_y = sensor_counts[-1], rmse_values[-1]  # No increasing RMSE found\n",
    "\n",
    "    fig = plt.figure(figsize=(3, 3))\n",
    "    plt.plot(sensor_counts, rmse_values, marker=\"o\", linestyle=\"--\", color=\"black\")\n",
    "    # Highlight the first increasing point\n",
    "    if highlight_x is not None:\n",
    "        plt.scatter(highlight_x, highlight_y, color=\"white\", edgecolors=\"black\", s=100, label=\"First Increase\")\n",
    "\n",
    "    plt.xlabel(\"Sensing Nodes\")\n",
    "    plt.ylabel(\"RMSE (Â°C)\")\n",
    "    plt.xticks(sensor_counts) \n",
    "    plt.yticks(yticks)\n",
    "    plt.text(0.5, -0.25, subfig, ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
    "    fig.savefig(figure + '.jpg', dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_sensors(df, \"benton-city\", \"air_temperature\", figure='Figures/Figure 4a', yticks=np.arange(0.22, 0.3, 0.01), subfig=\"(a)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_sensors(df, \"benton-city\", \"leaf_temperature\", figure='Figures/Figure 4b', yticks=np.arange(0.46, 0.52, 0.01), subfig='(b)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_sensors(df, \"sunnyside\", \"air_temperature\", figure='Figures/Figure 4c', yticks=np.arange(1, 8, 1), subfig='(c)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_sensors(df, \"sunnyside\", \"leaf_temperature\", figure='Figures/Figure 4d', yticks=np.arange(1, 8, 1), subfig='(d)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Sunnyside air temperature map '''\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# Load Sensor Metadata (Latitude, Longitude, Elevation)\n",
    "# -------------------------------------------\n",
    "# Assume you have a dataframe `sensor_metadata`\n",
    "# Columns: [\"sensor_id\", \"latitude\", \"longitude\", \"elevation\"]\n",
    "sensor_metadata = pd.read_csv(\" \")  # Load sensor metadata\n",
    "\n",
    "sensor_metadata.columns = [\"id\", \"latitude\", \"longitude\", \"name\", \"site\", \"elevation\"]\n",
    "\n",
    "# -------------------------------------------\n",
    "# Filter Sensors by Site (Only Sunnyside)\n",
    "# -------------------------------------------\n",
    "sunnyside_sensors = sensor_metadata[sensor_metadata[\"site\"] == \"sunnyside\"]\n",
    "\n",
    "# -------------------------------------------\n",
    "# Select Sensors by ID (From QR-POD Optimization)\n",
    "# -------------------------------------------\n",
    "selected_sensor_ids = [3, 0, 2, 4]  # Example selected sensors\n",
    "\n",
    "# Extract only the selected sensors from Sunnyside\n",
    "selected_sensors_df = sunnyside_sensors[sunnyside_sensors[\"id\"].isin(selected_sensor_ids)]\n",
    "\n",
    "# -------------------------------------------\n",
    "# Plot Selected Sensor Locations\n",
    "# -------------------------------------------\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "\n",
    "# Initialize Basemap for Sunnyside region\n",
    "m = Basemap(projection=\"merc\",\n",
    "            llcrnrlat=min(sunnyside_sensors[\"latitude\"]) - 0.001,\n",
    "            urcrnrlat=max(sunnyside_sensors[\"latitude\"]) + 0.001,\n",
    "            llcrnrlon=min(sunnyside_sensors[\"longitude\"]) - 0.001,\n",
    "            urcrnrlon=max(sunnyside_sensors[\"longitude\"]) + 0.001,\n",
    "            resolution=\"i\")\n",
    "\n",
    "m.drawcoastlines()\n",
    "m.drawcountries()\n",
    "m.drawrivers()\n",
    "m.drawmapboundary(fill_color=\"lightblue\")\n",
    "m.fillcontinents(color=\"whitesmoke\", lake_color=\"lightblue\")\n",
    "\n",
    "# Convert latitude/longitude to map coordinates\n",
    "x, y = m(selected_sensors_df[\"longitude\"].values, selected_sensors_df[\"latitude\"].values)\n",
    "\n",
    "# Plot Selected Sensors\n",
    "plt.scatter(x, y, s=10)\n",
    "\n",
    "elevations = selected_sensors_df[\"elevation\"].values\n",
    "sc = plt.scatter(x, y, s=100, c=elevations, cmap=\"terrain\",marker=\"o\", edgecolor=\"black\", label=\"Nodes\")\n",
    "\n",
    "# Add colorbar\n",
    "# cbar = plt.colorbar(sc)\n",
    "# cbar.set_label(\"Elevation (m)\")\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "wind_machine_df = sunnyside_sensors[sunnyside_sensors[\"name\"].str.contains(\"wind-machine\", case=False)]\n",
    "x_wind, y_wind = m(wind_machine_df[\"longitude\"].values, wind_machine_df[\"latitude\"].values)\n",
    "plt.scatter(x_wind, y_wind, s=150, c=\"black\", marker=\"X\", edgecolor=\"black\", linewidth=1, label=\"Wind Machine\")\n",
    "\n",
    "\n",
    "plt.annotate(\"N\", xy=(0.95, 0.84), xycoords=\"axes fraction\", fontsize=14, fontweight=\"bold\", ha=\"center\", va=\"center\")\n",
    "# Define arrow location (top-right of the plot)\n",
    "arrow_x = 0.95\n",
    "arrow_y = 0.90\n",
    "\n",
    "# Add a QGIS-style north arrow (bold triangle)\n",
    "north_arrow = patches.RegularPolygon((arrow_x, arrow_y), numVertices=3, radius=0.03, orientation=not(np.pi),\n",
    "                                     transform=ax.transAxes, color=\"black\")\n",
    "ax.add_patch(north_arrow)\n",
    "\n",
    "scale_length_m = 50  # Define scale bar length in meters\n",
    "\n",
    "# ðŸ”¹ Position for Scale Bar (bottom-right corner)\n",
    "scale_lat_start = min(sunnyside_sensors[\"latitude\"]) - 0.0005\n",
    "scale_lon_start = max(sunnyside_sensors[\"longitude\"]) - 0.00000001\n",
    "\n",
    "# ðŸ”¹ Convert to Map Coordinates\n",
    "scale_x_start, scale_y_start = m(scale_lon_start, scale_lat_start)\n",
    "scale_x_end, _ = m(scale_lon_start + 0.0001333 * 3, scale_lat_start)  # Convert 10m to degrees\n",
    "\n",
    "# ðŸ”¹ Draw the Scale Bar using Rectangle Patch\n",
    "scale_bar_width = scale_x_end - scale_x_start\n",
    "scale_bar_height = 4  # Adjust height for visibility\n",
    "\n",
    "scale_bar = patches.Rectangle((scale_x_start, scale_y_start), scale_bar_width, scale_bar_height,\n",
    "                              edgecolor=\"black\", facecolor=\"black\", linewidth=1)\n",
    "\n",
    "# ðŸ”¹ Add Scale Bar to the Plot\n",
    "ax = plt.gca()\n",
    "ax.add_patch(scale_bar)\n",
    "\n",
    "# ðŸ”¹ Add Scale Label (Centered on Scale Bar)\n",
    "plt.text((scale_x_start + scale_x_end) / 2, scale_y_start - 20, f\"{scale_length_m} m\",\n",
    "         fontsize=10, ha=\"center\", va=\"top\", color=\"black\")\n",
    "\n",
    "# plt.subplots_adjust(bottom=-0.2)  # Increase the bottom margin (adjust as needed)\n",
    "\n",
    "text = plt.text(0.5, -0.1, \"(c)\", ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
    "# Titles & Legend\n",
    "fig.savefig(\"Figures/Figure 5c\" + '.jpg', dpi=600, bbox_inches='tight', bbox_extra_artists=[text])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Sunnyside bud temperature map '''\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# Load Sensor Metadata (Latitude, Longitude, Elevation)\n",
    "# -------------------------------------------\n",
    "# Assume you have a dataframe `sensor_metadata`\n",
    "# Columns: [\"sensor_id\", \"latitude\", \"longitude\", \"elevation\"]\n",
    "sensor_metadata = pd.read_csv(\" \")  # Load sensor metadata\n",
    "\n",
    "sensor_metadata.columns = [\"id\", \"latitude\", \"longitude\", \"name\", \"site\", \"elevation\"]\n",
    "\n",
    "# -------------------------------------------\n",
    "# Filter Sensors by Site (Only Sunnyside)\n",
    "# -------------------------------------------\n",
    "sunnyside_sensors = sensor_metadata[sensor_metadata[\"site\"] == \"sunnyside\"]\n",
    "\n",
    "# -------------------------------------------\n",
    "# Select Sensors by ID (From QR-POD Optimization)\n",
    "# -------------------------------------------\n",
    "selected_sensor_ids = [3, 0, 2, 4, 5, 1]  # Example selected sensors\n",
    "\n",
    "# Extract only the selected sensors from Sunnyside\n",
    "selected_sensors_df = sunnyside_sensors[sunnyside_sensors[\"id\"].isin(selected_sensor_ids)]\n",
    "\n",
    "# -------------------------------------------\n",
    "# Plot Selected Sensor Locations\n",
    "# -------------------------------------------\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "\n",
    "# Initialize Basemap for Sunnyside region\n",
    "m = Basemap(projection=\"merc\",\n",
    "            llcrnrlat=min(sunnyside_sensors[\"latitude\"]) - 0.001,\n",
    "            urcrnrlat=max(sunnyside_sensors[\"latitude\"]) + 0.001,\n",
    "            llcrnrlon=min(sunnyside_sensors[\"longitude\"]) - 0.001,\n",
    "            urcrnrlon=max(sunnyside_sensors[\"longitude\"]) + 0.001,\n",
    "            resolution=\"i\")\n",
    "\n",
    "m.drawcoastlines()\n",
    "m.drawcountries()\n",
    "m.drawrivers()\n",
    "m.drawmapboundary(fill_color=\"lightblue\")\n",
    "m.fillcontinents(color=\"whitesmoke\", lake_color=\"lightblue\")\n",
    "\n",
    "# Convert latitude/longitude to map coordinates\n",
    "x, y = m(selected_sensors_df[\"longitude\"].values, selected_sensors_df[\"latitude\"].values)\n",
    "\n",
    "# Plot Selected Sensors\n",
    "plt.scatter(x, y, s=10)\n",
    "\n",
    "elevations = selected_sensors_df[\"elevation\"].values\n",
    "sc = plt.scatter(x, y, s=100, c=elevations, cmap=\"terrain\",marker=\"o\", edgecolor=\"black\", label=\"Nodes\")\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.set_label(\"Elevation (m)\")\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "wind_machine_df = sunnyside_sensors[sunnyside_sensors[\"name\"].str.contains(\"wind-machine\", case=False)]\n",
    "x_wind, y_wind = m(wind_machine_df[\"longitude\"].values, wind_machine_df[\"latitude\"].values)\n",
    "plt.scatter(x_wind, y_wind, s=150, c=\"black\", marker=\"X\", edgecolor=\"black\", linewidth=1, label=\"Wind Machine\")\n",
    "\n",
    "\n",
    "plt.annotate(\"N\", xy=(0.95, 0.84), xycoords=\"axes fraction\", fontsize=14, fontweight=\"bold\", ha=\"center\", va=\"center\")\n",
    "# Define arrow location (top-right of the plot)\n",
    "arrow_x = 0.95\n",
    "arrow_y = 0.90\n",
    "\n",
    "# Add a QGIS-style north arrow (bold triangle)\n",
    "north_arrow = patches.RegularPolygon((arrow_x, arrow_y), numVertices=3, radius=0.03, orientation=not(np.pi),\n",
    "                                     transform=ax.transAxes, color=\"black\")\n",
    "ax.add_patch(north_arrow)\n",
    "\n",
    "scale_length_m = 50  # Define scale bar length in meters\n",
    "\n",
    "# ðŸ”¹ Position for Scale Bar (bottom-right corner)\n",
    "scale_lat_start = min(sunnyside_sensors[\"latitude\"]) - 0.0005\n",
    "scale_lon_start = max(sunnyside_sensors[\"longitude\"]) - 0.00000001\n",
    "\n",
    "# ðŸ”¹ Convert to Map Coordinates\n",
    "scale_x_start, scale_y_start = m(scale_lon_start, scale_lat_start)\n",
    "scale_x_end, _ = m(scale_lon_start + 0.0001333 * 3, scale_lat_start)  # Convert 10m to degrees\n",
    "\n",
    "# ðŸ”¹ Draw the Scale Bar using Rectangle Patch\n",
    "scale_bar_width = scale_x_end - scale_x_start\n",
    "scale_bar_height = 4  # Adjust height for visibility\n",
    "\n",
    "scale_bar = patches.Rectangle((scale_x_start, scale_y_start), scale_bar_width, scale_bar_height,\n",
    "                              edgecolor=\"black\", facecolor=\"black\", linewidth=1)\n",
    "\n",
    "# ðŸ”¹ Add Scale Bar to the Plot\n",
    "ax = plt.gca()\n",
    "ax.add_patch(scale_bar)\n",
    "\n",
    "# ðŸ”¹ Add Scale Label (Centered on Scale Bar)\n",
    "plt.text((scale_x_start + scale_x_end) / 2, scale_y_start - 20, f\"{scale_length_m} m\",\n",
    "         fontsize=10, ha=\"center\", va=\"top\", color=\"black\")\n",
    "\n",
    "plt.text(0.5, -0.1, \"(d)\", ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
    "\n",
    "# Titles & Legend\n",
    "fig.savefig(\"Figures/Figure 5d\" + '.jpg', dpi=600, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Benton City Bud temperautre optimized nodes'''\n",
    "\n",
    "sensor_metadata = pd.read_csv(\" \")  # Load sensor metadata\n",
    "\n",
    "sensor_metadata.columns = [\"id\", \"latitude\", \"longitude\", \"name\", \"site\", \"elevation\"]\n",
    "\n",
    "# -------------------------------------------\n",
    "# Filter Sensors by Site (Only Sunnyside)\n",
    "# -------------------------------------------\n",
    "sunnyside_sensors = sensor_metadata[sensor_metadata[\"site\"] == \"benton-city\"]\n",
    "\n",
    "# -------------------------------------------\n",
    "#  Select Sensors by ID (From QR-POD Optimization)\n",
    "# -------------------------------------------\n",
    "selected_sensor_ids = [3, 0, 4]  # Example selected sensors\n",
    "\n",
    "# Extract only the selected sensors from Sunnyside\n",
    "selected_sensors_df = sunnyside_sensors[sunnyside_sensors[\"id\"].isin(selected_sensor_ids)]\n",
    "\n",
    "# -------------------------------------------\n",
    "#  Plot Selected Sensor Locations\n",
    "# -------------------------------------------\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "\n",
    "# Initialize Basemap for Sunnyside region\n",
    "m = Basemap(projection=\"merc\",\n",
    "            llcrnrlat=min(sunnyside_sensors[\"latitude\"]) - 0.001,\n",
    "            urcrnrlat=max(sunnyside_sensors[\"latitude\"]) + 0.001,\n",
    "            llcrnrlon=min(sunnyside_sensors[\"longitude\"]) - 0.001,\n",
    "            urcrnrlon=max(sunnyside_sensors[\"longitude\"]) + 0.001,\n",
    "            resolution=\"i\")\n",
    "\n",
    "m.drawcoastlines()\n",
    "m.drawcountries()\n",
    "m.drawrivers()\n",
    "m.drawmapboundary(fill_color=\"lightblue\")\n",
    "m.fillcontinents(color=\"whitesmoke\", lake_color=\"lightblue\")\n",
    "\n",
    "# Convert latitude/longitude to map coordinates\n",
    "x, y = m(selected_sensors_df[\"longitude\"].values, selected_sensors_df[\"latitude\"].values)\n",
    "\n",
    "# Plot Selected Sensors\n",
    "plt.scatter(x, y, s=10)\n",
    "\n",
    "elevations = selected_sensors_df[\"elevation\"].values\n",
    "sc = plt.scatter(x, y, s=100, c=elevations, cmap=\"terrain\", edgecolor=\"black\", label=\"Nodes\")\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.set_label(\"Elevation (m)\")\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "wind_machine_df = sunnyside_sensors[sunnyside_sensors[\"name\"].str.contains(\"wind-machine\", case=False)]\n",
    "x_wind, y_wind = m(wind_machine_df[\"longitude\"].values, wind_machine_df[\"latitude\"].values)\n",
    "plt.scatter(x_wind, y_wind, s=150, c=\"black\", marker=\"X\", edgecolor=\"black\", linewidth=1, label=\"Wind Machine\")\n",
    "\n",
    "\n",
    "plt.annotate(\"N\", xy=(0.95, 0.84), xycoords=\"axes fraction\", fontsize=14, fontweight=\"bold\", ha=\"center\", va=\"center\")\n",
    "# Define arrow location (top-right of the plot)\n",
    "arrow_x = 0.95\n",
    "arrow_y = 0.90\n",
    "\n",
    "# Add a QGIS-style north arrow (bold triangle)\n",
    "north_arrow = patches.RegularPolygon((arrow_x, arrow_y), numVertices=3, radius=0.03, orientation=not(np.pi),\n",
    "                                     transform=ax.transAxes, color=\"black\")\n",
    "ax.add_patch(north_arrow)\n",
    "\n",
    "\n",
    "scale_length_m = 50  # Define scale bar length in meters\n",
    "\n",
    "# ðŸ”¹ Position for Scale Bar (bottom-right corner)\n",
    "scale_lat_start = min(sunnyside_sensors[\"latitude\"]) - 0.0005\n",
    "scale_lon_start = max(sunnyside_sensors[\"longitude\"]) - 0.00000001\n",
    "\n",
    "# ðŸ”¹ Convert to Map Coordinates\n",
    "scale_x_start, scale_y_start = m(scale_lon_start, scale_lat_start)\n",
    "scale_x_end, _ = m(scale_lon_start + 0.0001333 * 5, scale_lat_start)  # Convert 10m to degrees\n",
    "\n",
    "# ðŸ”¹ Draw the Scale Bar using Rectangle Patch\n",
    "scale_bar_width = scale_x_end - scale_x_start\n",
    "scale_bar_height = 4  # Adjust height for visibility\n",
    "\n",
    "scale_bar = patches.Rectangle((scale_x_start, scale_y_start), scale_bar_width, scale_bar_height,\n",
    "                              edgecolor=\"black\", facecolor=\"black\", linewidth=1)\n",
    "\n",
    "# ðŸ”¹ Add Scale Bar to the Plot\n",
    "ax = plt.gca()\n",
    "ax.add_patch(scale_bar)\n",
    "\n",
    "# ðŸ”¹ Add Scale Label (Centered on Scale Bar)\n",
    "plt.text((scale_x_start + scale_x_end) / 2, scale_y_start - 20, f\"{scale_length_m} m\",\n",
    "         fontsize=10, ha=\"center\", va=\"top\", color=\"black\")\n",
    "\n",
    "\n",
    "plt.text(0.5, -0.1, \"(b)\", ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
    "\n",
    "# Titles & Legend\n",
    "fig.savefig(\"Figures/Figure 5b\" + '.jpg', dpi=600, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Benton City Air temperautre optimized nodes'''\n",
    "\n",
    "\n",
    "sensor_metadata = pd.read_csv(\" \")  # Load sensor metadata\n",
    "\n",
    "sensor_metadata.columns = [\"id\", \"latitude\", \"longitude\", \"name\", \"site\", \"elevation\"]\n",
    "\n",
    "# -------------------------------------------\n",
    "# Filter Sensors by Site (Only Sunnyside)\n",
    "# -------------------------------------------\n",
    "sunnyside_sensors = sensor_metadata[sensor_metadata[\"site\"] == \"benton-city\"]\n",
    "\n",
    "# -------------------------------------------\n",
    "# Select Sensors by ID (From QR-POD Optimization)\n",
    "# -------------------------------------------\n",
    "selected_sensor_ids = [0, 4]  # Example selected sensors\n",
    "\n",
    "# Extract only the selected sensors from Sunnyside\n",
    "selected_sensors_df = sunnyside_sensors[sunnyside_sensors[\"id\"].isin(selected_sensor_ids)]\n",
    "\n",
    "# -------------------------------------------\n",
    "# Plot Selected Sensor Locations\n",
    "# -------------------------------------------\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "\n",
    "# Initialize Basemap for Sunnyside region\n",
    "m = Basemap(projection=\"merc\",\n",
    "            llcrnrlat=min(sunnyside_sensors[\"latitude\"]) - 0.001,\n",
    "            urcrnrlat=max(sunnyside_sensors[\"latitude\"]) + 0.001,\n",
    "            llcrnrlon=min(sunnyside_sensors[\"longitude\"]) - 0.001,\n",
    "            urcrnrlon=max(sunnyside_sensors[\"longitude\"]) + 0.001,\n",
    "            resolution=\"i\")\n",
    "\n",
    "m.drawcoastlines()\n",
    "m.drawcountries()\n",
    "m.drawrivers()\n",
    "m.drawmapboundary(fill_color=\"lightblue\")\n",
    "m.fillcontinents(color=\"whitesmoke\", lake_color=\"lightblue\")\n",
    "\n",
    "# Convert latitude/longitude to map coordinates\n",
    "x, y = m(selected_sensors_df[\"longitude\"].values, selected_sensors_df[\"latitude\"].values)\n",
    "\n",
    "# Plot Selected Sensors\n",
    "plt.scatter(x, y, s=10)\n",
    "\n",
    "elevations = selected_sensors_df[\"elevation\"].values\n",
    "sc = plt.scatter(x, y, s=100, c=elevations, cmap=\"terrain\", edgecolor=\"black\", label=\"SN\")\n",
    "\n",
    "# Add colorbar\n",
    "# cbar = plt.colorbar()\n",
    "# cbar.set_label(\"Elevation (m)\")\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "wind_machine_df = sunnyside_sensors[sunnyside_sensors[\"name\"].str.contains(\"wind-machine\", case=False)]\n",
    "x_wind, y_wind = m(wind_machine_df[\"longitude\"].values, wind_machine_df[\"latitude\"].values)\n",
    "plt.scatter(x_wind, y_wind, s=150, c=\"black\", marker=\"X\", edgecolor=\"black\", linewidth=1, label=\"WM\")\n",
    "\n",
    "\n",
    "plt.annotate(\"N\", xy=(0.95, 0.84), xycoords=\"axes fraction\", fontsize=14, fontweight=\"bold\", ha=\"center\", va=\"center\")\n",
    "# Define arrow location (top-right of the plot)\n",
    "arrow_x = 0.95\n",
    "arrow_y = 0.90\n",
    "\n",
    "# Add a QGIS-style north arrow (bold triangle)\n",
    "north_arrow = patches.RegularPolygon((arrow_x, arrow_y), numVertices=3, radius=0.03, orientation=not(np.pi),\n",
    "                                     transform=ax.transAxes, color=\"black\")\n",
    "ax.add_patch(north_arrow)\n",
    "\n",
    "\n",
    "scale_length_m = 50  # Define scale bar length in meters\n",
    "\n",
    "# Position for Scale Bar (bottom-right corner)\n",
    "scale_lat_start = min(sunnyside_sensors[\"latitude\"]) - 0.0005\n",
    "scale_lon_start = max(sunnyside_sensors[\"longitude\"]) - 0.00000001\n",
    "\n",
    "# Convert to Map Coordinates\n",
    "scale_x_start, scale_y_start = m(scale_lon_start, scale_lat_start)\n",
    "scale_x_end, _ = m(scale_lon_start + 0.0001333 * 5, scale_lat_start)  # Convert 10m to degrees\n",
    "\n",
    "# Draw the Scale Bar using Rectangle Patch\n",
    "scale_bar_width = scale_x_end - scale_x_start\n",
    "scale_bar_height = 4  # Adjust height for visibility\n",
    "\n",
    "scale_bar = patches.Rectangle((scale_x_start, scale_y_start), scale_bar_width, scale_bar_height,\n",
    "                              edgecolor=\"black\", facecolor=\"black\", linewidth=1)\n",
    "\n",
    "# Add Scale Bar to the Plot\n",
    "ax = plt.gca()\n",
    "ax.add_patch(scale_bar)\n",
    "\n",
    "# Add Scale Label (Centered on Scale Bar)\n",
    "plt.text((scale_x_start + scale_x_end) / 2, scale_y_start - 20, f\"{scale_length_m} m\",\n",
    "         fontsize=10, ha=\"center\", va=\"top\", color=\"black\")\n",
    "\n",
    "# Titles & Legend\n",
    "plt.legend()\n",
    "text = plt.text(0.5, -0.1, \"(a)\", ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
    "\n",
    "fig.savefig(\"Figures/Figure 5a\" + '.jpg', dpi=600, bbox_inches='tight', bbox_extra_artists=[text])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "\n",
    "file_path = \" \"  # Update with your actual file path\n",
    "df = pd.read_csv(file_path, parse_dates=[\"datetime\"])\n",
    "\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "\n",
    "field = 'sunnyside'\n",
    "df = df[(df[\"field\"] == field) &\n",
    "        (df[\"datetime\"].dt.year.isin([2024])) \n",
    "        &\n",
    "        (df[\"datetime\"].dt.month.isin([3, 4]))\n",
    "        ]\n",
    "\n",
    "df = df[[\"datetime\", \"location\", \"air_temperature\", \"leaf_temperature\"]]\n",
    "df = df[(df['datetime'].dt.hour >= 0) & (df['datetime'].dt.hour < 8)]\n",
    "\n",
    "pivot_air = df.pivot(index=\"datetime\", columns=\"location\", values=\"air_temperature\")\n",
    "pivot_leaf = df.pivot(index=\"datetime\", columns=\"location\", values=\"leaf_temperature\")\n",
    "pivot_air.interpolate(method='linear', inplace=True, axis=1)\n",
    "pivot_leaf.interpolate(method='linear', inplace=True, axis=1)\n",
    "\n",
    "pivot_air = pivot_air.dropna()\n",
    "pivot_leaf = pivot_leaf.dropna()\n",
    "# ---------------------------------------\n",
    "# 1ï¸âƒ£ Load Your Temperature Data\n",
    "# ---------------------------------------\n",
    "# Assuming pivot_air and pivot_leaf are (timestamps x nodes) DataFrames\n",
    "# where each column represents a sensor node and each row represents a time step.\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "air_temp_data = pivot_air.values  # Shape: (time, nodes)\n",
    "leaf_temp_data = pivot_leaf.values  # Shape: (time, nodes)\n",
    "\n",
    "# Sampling frequency (assume hourly data)\n",
    "dt = 5/60  # Time step in hours\n",
    "Fs = 1 / dt  # Sampling frequency (per hour)\n",
    "N = air_temp_data.shape[0]  # Number of time points\n",
    "freqs = fftfreq(N, d=dt)  # Frequency bins\n",
    "\n",
    "# Compute Fourier transforms\n",
    "fft_air = fft(air_temp_data, axis=0)\n",
    "fft_leaf = fft(leaf_temp_data, axis=0)\n",
    "\n",
    "# Compute magnitudes and phases\n",
    "magnitude_air = np.abs(fft_air)\n",
    "magnitude_leaf = np.abs(fft_leaf)\n",
    "phase_air = np.angle(fft_air)\n",
    "phase_leaf = np.angle(fft_leaf)\n",
    "\n",
    "# Compute phase difference at diurnal frequency (1 cycle per 24 hours)\n",
    "diurnal_freq_idx = np.argmin(np.abs(freqs - 1/0.5))  # Closest to 1/24 hour^-1\n",
    "wind_machine_index = 5  \n",
    "\n",
    "# Compute phase difference relative to the wind machine\n",
    "phase_diff_air_diurnal = phase_air[diurnal_freq_idx, :] - phase_air[diurnal_freq_idx, wind_machine_index]\n",
    "phase_diff_leaf_diurnal = phase_leaf[diurnal_freq_idx, :] - phase_leaf[diurnal_freq_idx, wind_machine_index]\n",
    "\n",
    "# Convert phase difference to time lag in hours\n",
    "time_lag_air_hours = phase_diff_air_diurnal / (2 * np.pi * (1))  # Convert to hours\n",
    "time_lag_leaf_hours = phase_diff_leaf_diurnal / (2 * np.pi * (1))  # Convert to hours\n",
    "\n",
    "num_sensors = air_temp_data.shape[1]\n",
    "\n",
    "x = np.arange(num_sensors)  # Sensor indices\n",
    "width = 0.3  # Width of bars\n",
    "\n",
    "# ---------------------------------------\n",
    "# Plot Magnitude Spectrum (High & Low Frequencies)\n",
    "# ---------------------------------------\n",
    "\n",
    "low_freq_range = (freqs > 0) & (freqs < 1/6)  # Below 6-hour periodicity\n",
    "high_freq_range = (freqs > 1/6) & (freqs < 1/0.5)  # Between 6-hour and 2-hour periodicity\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(3, 2))\n",
    "# High-Frequency Components (Short-Term Variability)\n",
    "plt.bar(x - width/2, np.mean(magnitude_air[high_freq_range, :], axis=0), width=width, alpha=0.9, color=\"darkorange\", label=\"Air Temperature\")\n",
    "plt.bar(x + width/2, np.mean(magnitude_leaf[high_freq_range, :], axis=0), width=width, alpha=0.9, color=\"darkgreen\", label=\"Bud Tissue Temperature\")\n",
    "plt.xlabel(\"Sensor Node\")\n",
    "plt.ylabel(\"Mean Magnitude\")\n",
    "# plt.title(\"High Frequency Components\")\n",
    "plt.xticks(x, ['SN1', 'SN2', 'SN3', 'SN4', 'SN5', 'SN6'])\n",
    "plt.yticks(range(0, 150, 20))\n",
    "\n",
    "# plt.legend()\n",
    "plt.text(0.5, -0.4, '(b)', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
    "\n",
    "fig.savefig(\"Figures/Figure 2b\" + '.jpg', dpi=600, bbox_inches='tight')\n",
    "# ---------------------------------------\n",
    "# Plot Phase Difference at Diurnal Frequency\n",
    "# ---------------------------------------\n",
    "\n",
    "x = np.arange(5)  # Sensor indices\n",
    "width = 0.2\n",
    "fig = plt.figure(figsize=(3, 2))\n",
    "\n",
    "# Plot air temperature phase lag (left bars)\n",
    "plt.bar(x - width/2, -np.abs(time_lag_air_hours[:-1]), width=width, label=\"Air Temperature\", color=\"darkorange\")\n",
    "\n",
    "# Plot leaf temperature phase lag (right bars)\n",
    "plt.bar(x + width/2,  -np.abs(time_lag_leaf_hours[:-1]), width=width, label=\"Bud Tissue Temperature\", color=\"darkgreen\")\n",
    "\n",
    "plt.xlabel(\"Sensor Node\")\n",
    "plt.ylabel(\"Time Lag (H)\")\n",
    "# plt.title(\"Phase Lag at Diurnal Frequency (Relative to Wind Machine)\")\n",
    "\n",
    "plt.xticks(x, ['SN1', 'SN2', 'SN3', 'SN4', 'SN5'])\n",
    "# plt.legend()\n",
    "# plt.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.text(0.5, -0.4, '(d)', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
    "fig.savefig(\"Figures/Figure 2d\" + '.jpg', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "\n",
    "file_path = \" \"  # Update with your actual file path\n",
    "df = pd.read_csv(file_path, parse_dates=[\"datetime\"])\n",
    "\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "\n",
    "field = 'benton-city'\n",
    "df = df[(df[\"field\"] == field) &\n",
    "        (df[\"datetime\"].dt.year.isin([2023, 2024])) \n",
    "        &\n",
    "        (df[\"datetime\"].dt.month.isin([3, 4]))\n",
    "        ]\n",
    "\n",
    "df = df[[\"datetime\", \"location\", \"air_temperature\", \"leaf_temperature\"]]\n",
    "df = df[(df['datetime'].dt.hour >= 0) & (df['datetime'].dt.hour < 8)]\n",
    "\n",
    "pivot_air = df.pivot(index=\"datetime\", columns=\"location\", values=\"air_temperature\")\n",
    "pivot_leaf = df.pivot(index=\"datetime\", columns=\"location\", values=\"leaf_temperature\")\n",
    "pivot_air.interpolate(method='linear', inplace=True, axis=1)\n",
    "pivot_leaf.interpolate(method='linear', inplace=True, axis=1)\n",
    "\n",
    "pivot_air = pivot_air.dropna()\n",
    "pivot_leaf = pivot_leaf.dropna()\n",
    "# ---------------------------------------\n",
    "# Load Your Temperature Data\n",
    "# ---------------------------------------\n",
    "# Assuming pivot_air and pivot_leaf are (timestamps x nodes) DataFrames\n",
    "# where each column represents a sensor node and each row represents a time step.\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "air_temp_data = pivot_air.values  # Shape: (time, nodes)\n",
    "leaf_temp_data = pivot_leaf.values  # Shape: (time, nodes)\n",
    "\n",
    "# Sampling frequency (assume hourly data)\n",
    "dt = 5/60  # Time step in hours\n",
    "Fs = 1 / dt  # Sampling frequency (per hour)\n",
    "N = air_temp_data.shape[0]  # Number of time points\n",
    "freqs = fftfreq(N, d=dt)  # Frequency bins\n",
    "\n",
    "# Compute Fourier transforms\n",
    "fft_air = fft(air_temp_data, axis=0)\n",
    "fft_leaf = fft(leaf_temp_data, axis=0)\n",
    "\n",
    "# Compute magnitudes and phases\n",
    "magnitude_air = np.abs(fft_air)\n",
    "magnitude_leaf = np.abs(fft_leaf)\n",
    "phase_air = np.angle(fft_air)\n",
    "phase_leaf = np.angle(fft_leaf)\n",
    "\n",
    "# Compute phase difference at diurnal frequency (1 cycle per 24 hours)\n",
    "diurnal_freq_idx = np.argmin(np.abs(freqs - 1/2))  # Closest to 1/24 hour^-1\n",
    "wind_machine_index = 5  \n",
    "\n",
    "# Compute phase difference relative to the wind machine\n",
    "phase_diff_air_diurnal = phase_air[diurnal_freq_idx, :] - phase_air[diurnal_freq_idx, wind_machine_index]\n",
    "phase_diff_leaf_diurnal = phase_leaf[diurnal_freq_idx, :] - phase_leaf[diurnal_freq_idx, wind_machine_index]\n",
    "\n",
    "# Convert phase difference to time lag in hours\n",
    "time_lag_air_hours = phase_diff_air_diurnal / (2 * np.pi * (1/2))  # Convert to hours\n",
    "time_lag_leaf_hours = phase_diff_leaf_diurnal / (2 * np.pi * (1/2))  # Convert to hours\n",
    "\n",
    "num_sensors = air_temp_data.shape[1]\n",
    "\n",
    "x = np.arange(num_sensors)  # Sensor indices\n",
    "width = 0.3  # Width of bars\n",
    "\n",
    "# ---------------------------------------\n",
    "# Plot Magnitude Spectrum (High & Low Frequencies)\n",
    "# ---------------------------------------\n",
    "\n",
    "low_freq_range = (freqs > 0) & (freqs < 1/6)  # Below 6-hour periodicity\n",
    "high_freq_range = (freqs > 1/6) & (freqs < 1/0.5)  # Between 6-hour and 2-hour periodicity\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(3, 2))\n",
    "# High-Frequency Components (Short-Term Variability)\n",
    "plt.bar(x - width/2, np.mean(magnitude_air[high_freq_range, :], axis=0), width=width, alpha=0.9, color=\"darkorange\", label=r'$T_{a}$')\n",
    "plt.bar(x + width/2, np.mean(magnitude_leaf[high_freq_range, :], axis=0), width=width, alpha=0.9, color=\"darkgreen\", label=r'$T_{b}$')\n",
    "plt.xlabel(\"Sensor Node\")\n",
    "plt.ylabel(\"Mean Magnitude\")\n",
    "# plt.title(\"High Frequency Components\")\n",
    "plt.xticks(x, ['SN1', 'SN2', 'SN3', 'SN4', 'SN5', 'SN6'])\n",
    "plt.yticks(range(0, 150, 20))\n",
    "plt.legend(loc='upper left')\n",
    "# Add subcaption (a) at the bottom center\n",
    "plt.text(0.5, -0.4, '(a)', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
    "# plt.grid(True, linestyle=\":\", alpha=0.6)\n",
    "fig.savefig(\"Figures/Figure 2a\" + '.jpg', dpi=600, bbox_inches='tight')\n",
    "# ---------------------------------------\n",
    "# Plot Phase Difference at Diurnal Frequency\n",
    "# ---------------------------------------\n",
    "\n",
    "x = np.arange(5)  # Sensor indices\n",
    "width = 0.2\n",
    "fig = plt.figure(figsize=(3, 2))\n",
    "\n",
    "# Plot air temperature phase lag (left bars)\n",
    "plt.bar(x - width/2, -np.abs(time_lag_air_hours[:-1]), width=width, label=r'$T_{a}$', color=\"darkorange\")\n",
    "\n",
    "# Plot leaf temperature phase lag (right bars)\n",
    "plt.bar(x + width/2,  -np.abs(time_lag_leaf_hours[:-1]), width=width, label=r'$T_{b}$', color=\"darkgreen\")\n",
    "\n",
    "plt.xlabel(\"Sensor Node\")\n",
    "plt.ylabel(\"Time Lag (H)\")\n",
    "# plt.title(\"Phase Lag at Diurnal Frequency (Relative to Wind Machine)\")\n",
    "\n",
    "plt.xticks(x, ['SN1', 'SN2', 'SN3', 'SN4', 'SN5'])  # Ensure correct x-axis labels\n",
    "\n",
    "# plt.legend()\n",
    "# plt.grid(True, linestyle=':', alpha=0.6)\n",
    "# plt.tight_layout()\n",
    "plt.text(0.5, -0.4, '(c)', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
    "\n",
    "fig.savefig(\"Figures/Figure 2c\" + '.jpg', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_file = ' '\n",
    "ch_model_file = ' '\n",
    "\n",
    "# Read weather data (5-minute intervals)\n",
    "weather_df = pd.read_csv(weather_file, parse_dates=['datetime'])\n",
    "\n",
    "weather_df['datetime'] = pd.to_datetime(weather_df['datetime'], errors='coerce')\n",
    "\n",
    "weather_df = weather_df[(weather_df['datetime'].dt.year > 2022)]\n",
    "\n",
    "weather_df = weather_df[(weather_df['datetime'].dt.hour > 0) &  (weather_df['datetime'].dt.hour < 8)]\n",
    "# Extract Date from datetime for joining\n",
    "weather_df['Date'] = weather_df['datetime'].dt.normalize()  \n",
    "\n",
    "# Read combined CH model data (with LT10 thresholds)\n",
    "ch_model_df = pd.read_csv(ch_model_file, parse_dates=['Date'])\n",
    "\n",
    "ch_model_df['Date'] = pd.to_datetime(ch_model_df['Date'], errors='coerce') \n",
    "\n",
    "# Merge on 'Date' and 'field'\n",
    "merged_df = pd.merge(weather_df, ch_model_df, on=['Date', 'field'], how='inner')\n",
    "\n",
    "def compute_csdi(df):\n",
    "    \"\"\"\n",
    "    Computes the Cold Spell Duration Index (CSDI) per day.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with 'datetime', 'bud_temp', and 'field'.\n",
    "    - threshold: Temperature threshold for cold spell (e.g., LT10 value).\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with CSDI per day and field.\n",
    "    \"\"\"\n",
    "    # Flag cold events where bud temperature is below threshold\n",
    "    df['cold_event'] = df['air_temperature'] < df['chelan_LT10'] + 0.5\n",
    "\n",
    "    df['csmi'] = df.apply(lambda row: (row['chelan_LT10'] - row['air_temperature']) * (5 / 60) \n",
    "                          if row['air_temperature'] < row['chelan_LT10'] else 0, axis=1)\n",
    "\n",
    "\n",
    "    # Group by date and field to sum durations\n",
    "    csdi_df = df.groupby(['Date', 'field', 'location']).agg(\n",
    "        cold_duration=('cold_event', 'sum'),  # Count cold events (each row is a 5-min interval)\n",
    "        thrm_bud_min = ('thrm_bud_temp', 'min'),\n",
    "        chelan_LT10 = ('chelan_LT10', 'min'),\n",
    "        CSMI_sum=('csmi', 'sum'),  # Sum of CSMI over the day\n",
    "        CSMI_mean=('csmi', 'mean'),  # Mean CSMI per day\n",
    "        CSMI_max=('csmi', 'max'),  # Max CSMI per day\n",
    "        CSMI_min=('csmi', 'min')   # Min CSMI per day\n",
    "    ).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "    # Convert count to duration in hours (5 min intervals)\n",
    "    csdi_df['cold_duration_hours'] = csdi_df['cold_duration'] * (5 / 60)\n",
    "\n",
    "    # Normalize the CSDI (0 to 1 scale)\n",
    "    max_duration = csdi_df['cold_duration_hours'].max()\n",
    "    csdi_df['csdi_normalized'] = csdi_df['cold_duration_hours'] / max_duration if max_duration != 0 else 0\n",
    "\n",
    "    # Normalize CSMI for each field\n",
    "    def normalize_csmi(df):\n",
    "        max_csmi = df['CSMI_max'].max()\n",
    "        min_csmi = df['CSMI_min'].min()\n",
    "        df['csmi_normalized'] = (\n",
    "            (df['CSMI_max'] - df['CSMI_min']) / (df['CSMI_sum'] - df['CSMI_min'])\n",
    "            if max_csmi != min_csmi else 0\n",
    "        )\n",
    "        return df\n",
    "    \n",
    "    csdi_df = csdi_df.groupby(['Date', 'field', 'location']).apply(normalize_csmi).reset_index(drop=True)\n",
    "\n",
    "    return csdi_df\n",
    "\n",
    "\n",
    "daily_csdi = compute_csdi(merged_df)\n",
    "\n",
    "filtered_data = daily_csdi[daily_csdi['field'] == 'benton-city']\n",
    "filtered_data = filtered_data[filtered_data['cold_duration'] > 0]\n",
    "\n",
    "# Rename nodes to SN1, SN2, ..., SN6\n",
    "node_mapping = {\n",
    "    'node-1': 'SN1',\n",
    "    'node-2': 'SN2',\n",
    "    'node-3': 'SN3',\n",
    "    'node-4': 'SN4',\n",
    "    'node-5': 'SN5',\n",
    "    'wind-machine': 'SN6'\n",
    "}\n",
    "filtered_data['location'] = filtered_data['location'].map(node_mapping)\n",
    "\n",
    "pivot_data = filtered_data.pivot(index='Date', columns='location', values=['cold_duration_hours', 'thrm_bud_min'])\n",
    "\n",
    "\n",
    "# Plotting\n",
    "fig, ax1 = plt.subplots(figsize=(3, 2))\n",
    "\n",
    "# Bar plot for cold_duration_hours\n",
    "pivot_data['cold_duration_hours'].plot(kind='bar', ax=ax1, width=0.8, alpha=0.7, legend=False)\n",
    "\n",
    "# Set x-ticks to only dates with data\n",
    "ax1.set_xticks(range(len(pivot_data.index)))\n",
    "ax1.set_xticklabels(pivot_data.index.strftime('%Y-%m-%d'), rotation=90)\n",
    "\n",
    "# Add labels and title\n",
    "ax1.set_xlabel('Date (Y-m-d)')\n",
    "ax1.set_ylabel('ACH (Hours)')\n",
    "# ax1.set_title('Cold Duration Hours and Minimum Temperatures by Date and Location')\n",
    "\n",
    "ax1.set_yticks(range(7))\n",
    "\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "\n",
    "# Adjust layout\n",
    "plt.text(0.5, -0.8, '(a)', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
    "\n",
    "fig.savefig(\"Figures/Figure 3a\" + '.jpg', dpi=600, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_file = ' '\n",
    "ch_model_file = ' '\n",
    "\n",
    "# Read weather data (5-minute intervals)\n",
    "weather_df = pd.read_csv(weather_file, parse_dates=['datetime'])\n",
    "\n",
    "weather_df['datetime'] = pd.to_datetime(weather_df['datetime'], errors='coerce')\n",
    "\n",
    "weather_df = weather_df[(weather_df['datetime'].dt.year > 2022)]\n",
    "\n",
    "weather_df = weather_df[(weather_df['datetime'].dt.hour > 0) &  (weather_df['datetime'].dt.hour < 8)]\n",
    "# Extract Date from datetime for joining\n",
    "weather_df['Date'] = weather_df['datetime'].dt.normalize()  \n",
    "\n",
    "# Read combined CH model data (with LT10 thresholds)\n",
    "ch_model_df = pd.read_csv(ch_model_file, parse_dates=['Date'])\n",
    "\n",
    "ch_model_df['Date'] = pd.to_datetime(ch_model_df['Date'], errors='coerce') \n",
    "\n",
    "# Merge on 'Date' and 'field'\n",
    "merged_df = pd.merge(weather_df, ch_model_df, on=['Date', 'field'], how='inner')\n",
    "\n",
    "def compute_csdi(df):\n",
    "    \"\"\"\n",
    "    Computes the Cold Spell Duration Index (CSDI) per day.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with 'datetime', 'bud_temp', and 'field'.\n",
    "    - threshold: Temperature threshold for cold spell (e.g., LT10 value).\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with CSDI per day and field.\n",
    "    \"\"\"\n",
    "    # Flag cold events where bud temperature is below threshold\n",
    "    df['cold_event'] = df['air_temperature'] < df['chelan_LT10'] + 0.5\n",
    "\n",
    "    df['csmi'] = df.apply(lambda row: (row['chelan_LT10'] - row['air_temperature']) * (5 / 60) \n",
    "                          if row['air_temperature'] < row['chelan_LT10'] else 0, axis=1)\n",
    "\n",
    "\n",
    "    # Group by date and field to sum durations\n",
    "    csdi_df = df.groupby(['Date', 'field', 'location']).agg(\n",
    "        cold_duration=('cold_event', 'sum'),  # Count cold events (each row is a 5-min interval)\n",
    "        thrm_bud_min = ('thrm_bud_temp', 'min'),\n",
    "        chelan_LT10 = ('chelan_LT10', 'min'),\n",
    "        CSMI_sum=('csmi', 'sum'),  # Sum of CSMI over the day\n",
    "        CSMI_mean=('csmi', 'mean'),  # Mean CSMI per day\n",
    "        CSMI_max=('csmi', 'max'),  # Max CSMI per day\n",
    "        CSMI_min=('csmi', 'min')   # Min CSMI per day\n",
    "    ).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "    # Convert count to duration in hours (5 min intervals)\n",
    "    csdi_df['cold_duration_hours'] = csdi_df['cold_duration'] * (5 / 60)\n",
    "\n",
    "    # Normalize the CSDI (0 to 1 scale)\n",
    "    max_duration = csdi_df['cold_duration_hours'].max()\n",
    "    csdi_df['csdi_normalized'] = csdi_df['cold_duration_hours'] / max_duration if max_duration != 0 else 0\n",
    "\n",
    "    # Normalize CSMI for each field\n",
    "    def normalize_csmi(df):\n",
    "        max_csmi = df['CSMI_max'].max()\n",
    "        min_csmi = df['CSMI_min'].min()\n",
    "        df['csmi_normalized'] = (\n",
    "            (df['CSMI_max'] - df['CSMI_min']) / (df['CSMI_sum'] - df['CSMI_min'])\n",
    "            if max_csmi != min_csmi else 0\n",
    "        )\n",
    "        return df\n",
    "    \n",
    "    csdi_df = csdi_df.groupby(['Date', 'field', 'location']).apply(normalize_csmi).reset_index(drop=True)\n",
    "\n",
    "    return csdi_df\n",
    "\n",
    "\n",
    "daily_csdi = compute_csdi(merged_df)\n",
    "\n",
    "filtered_data = daily_csdi[daily_csdi['field'] == 'sunnyside']\n",
    "filtered_data = filtered_data[filtered_data['cold_duration'] > 0]\n",
    "\n",
    "# Rename nodes to SN1, SN2, ..., SN6\n",
    "node_mapping = {\n",
    "    'node-1': 'SN1',\n",
    "    'node-2': 'SN2',\n",
    "    'node-3': 'SN3',\n",
    "    'node-4': 'SN4',\n",
    "    'node-5': 'SN5',\n",
    "    'wind-machine': 'SN6'\n",
    "}\n",
    "filtered_data['location'] = filtered_data['location'].map(node_mapping)\n",
    "\n",
    "filtered_data = filtered_data[filtered_data['Date'].dt.year > 2023]\n",
    "\n",
    "pivot_data = filtered_data.pivot(index='Date', columns='location', values=['cold_duration_hours', 'thrm_bud_min'])\n",
    "\n",
    "\n",
    "# Plotting\n",
    "fig, ax1 = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "pivot_data['cold_duration_hours'].plot(kind='bar', ax=ax1, width=0.8, alpha=0.7)\n",
    "\n",
    "idx = pivot_data.index  # DatetimeIndex\n",
    "\n",
    "# -------- Lower ticks: the actual dates --------\n",
    "ax1.set_xticks(range(len(idx)))\n",
    "ax1.set_xticklabels(idx.strftime('%d'), rotation=45)\n",
    "\n",
    "ax1.set_yticks(range(7))\n",
    "\n",
    "# Add labels and title\n",
    "ax1.set_xlabel('Date (d)',fontsize=14)\n",
    "ax1.set_ylabel('ACH (Hours)', fontsize=14)\n",
    "ax1.tick_params(axis='both', labelsize=14)\n",
    "ax1.legend(fontsize=14)\n",
    "\n",
    "# Adjust layout\n",
    "# plt.text(0.5, -0.8, '(b)', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
    "\n",
    "fig.savefig(\"ACD Plot Y24\" + '.jpg', dpi=600, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
